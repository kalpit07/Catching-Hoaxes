{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data (df, train_data, test_data, labels_train, labels_test)\n",
    "\n",
    "import pickle\n",
    "\n",
    "df = pickle.load(open('pklFiles/df.pkl', 'rb'))\n",
    "train_data = pickle.load(open('pklFiles/train_data.pkl', 'rb'))\n",
    "test_data = pickle.load(open('pklFiles/test_data.pkl', 'rb'))\n",
    "train_labels = pickle.load(open('pklFiles/train_labels.pkl', 'rb'))\n",
    "test_labels = pickle.load(open('pklFiles/test_labels.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining variables for num_words, maxlen, output_dim\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "MAX_WORDS = 35000\n",
    "EMBEDDING_DIM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Dropout, Conv1D, MaxPooling1D, BatchNormalization, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "\n",
    "cnn_model = Sequential()\n",
    "\n",
    "cnn_model.add(Embedding(input_dim=MAX_WORDS, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
    "cnn_model.add(Dropout(rate=0.5))\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=10))\n",
    "\n",
    "cnn_model.add(Dropout(rate=0.5))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=10))\n",
    "\n",
    "cnn_model.add(Dropout(rate=0.5))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "cnn_model.add(Dense(units=128, activation='relu'))\n",
    "cnn_model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "130/130 [==============================] - 97s 742ms/step - loss: 0.5272 - acc: 0.7341 - val_loss: 3.0791 - val_acc: 0.5030\n",
      "Epoch 2/5\n",
      "130/130 [==============================] - 116s 895ms/step - loss: 0.1530 - acc: 0.9463 - val_loss: 2.0922 - val_acc: 0.5100\n",
      "Epoch 3/5\n",
      "130/130 [==============================] - 118s 908ms/step - loss: 0.0860 - acc: 0.9752 - val_loss: 0.4872 - val_acc: 0.7946\n",
      "Epoch 4/5\n",
      "130/130 [==============================] - 116s 894ms/step - loss: 0.0563 - acc: 0.9850 - val_loss: 0.1935 - val_acc: 0.9333\n",
      "Epoch 5/5\n",
      "130/130 [==============================] - 118s 910ms/step - loss: 0.0445 - acc: 0.9876 - val_loss: 0.1364 - val_acc: 0.9555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f450e9cc40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training CNN model\n",
    "\n",
    "cnn_model.fit(train_data, train_labels, \n",
    "              batch_size=128, \n",
    "              epochs=5, \n",
    "              validation_data=(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "\n",
    "predicted_labels = cnn_model.predict(test_data)\n",
    "print(predicted_labels.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : [0.98906819 0.9265233 ]\n",
      "Recall    : [0.92054264 0.98994734]\n",
      "F-score   : [0.95357591 0.95718584]\n",
      "Support   : [2064 2089]\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F-score, Support\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(test_labels, predicted_labels.round())\n",
    "\n",
    "print('Precision : {}'.format(precision))\n",
    "print('Recall    : {}'.format(recall))\n",
    "print('F-score   : {}'.format(fscore))\n",
    "print('Support   : {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      2064\n",
      "           1       0.93      0.99      0.96      2089\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      4153\n",
      "   macro avg       0.96      0.96      0.96      4153\n",
      "weighted avg       0.96      0.96      0.96      4153\n",
      " samples avg       0.96      0.96      0.96      4153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "\n",
    "print(classification_report(test_labels, predicted_labels.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save(\"Trained Models/cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input\n",
    "\n",
    "title = \"This security flaw puts millions of computers at risk for a serious (but unlikely) hack\"\n",
    "author = \"Clare Duffy\"\n",
    "text = \"New York (CNN Business)A new report from a Dutch security researcher details a hacking mechanism that targets a common feature on millions of computers: the Thunderbolt port. Bjorn Ruytenberg, a researcher at Eindhoven University in the Netherlands, identified a security flaw in the Thunderbolt port that could allow a hacker to break into a computer and access all of its data in a matter of minutes, even if the computer's owner has taken security precautions. If your computer has such a port, an attacker who gets brief physical access to it can read and copy all your data, even if your drive is encrypted and your computer is locked or set to sleep, Ruytenberg said in the report. He dubbed the hacking technique Thunderspy. Thunderspy is stealth, meaning that you cannot find any traces of the attack, he said. The attack also does not require any engagement on the part of the computer's user, unlike other types of attacks such as phishing. Developed by Intel (INTC) in 2011, the Thunderbolt port enables fast data transfers. It is present on many PC and Apple laptops and — increasingly — some desktops. Although Intel recently developed a tool to address security concerns with the port, it isn't available on computers manufactured before 2019. Ruytenberg demonstrated the attack, which took just about five minutes, in a YouTube video published along with the report. For its part, Intel says that if users take normal security precautions and don't leave their computers somewhere a hacker could access them for even a few minutes — even if they have encrypted drives — they shouldn't be too worried about this type of hack. While the Thunderspy attack is technically possible on many computers with a Thunderbolt port, it requires that the hacker gains physical access to the computer for several minutes — enough time to unscrew the back panel of a laptop, plug in a device to the Thunderbolt and override security features, reattach the back of the laptop and then access the computer's data. Most people likely do not have valuable enough data on their computers for a hacker to want to carry out such a targeted attack. Even beyond Thunderspy, security experts have long warned of risks that could come from letting a hacker gain physical access to a computer. A group of security researchers last year identified several vulnerabilities related to Thunderbolt ports. In response, Intel created a tool called Kernel Direct Memory Access (DMA) to mitigate such attacks, which was implemented into major operating systems from Windows, Linux and Mac in 2019, Jerry Bryant, Intel's director of communications for product assurance and security, said in a blog post Sunday. The underlying vulnerability identified by Ruytenberg's Thunderspy technique is the same as those addressed by that mitigation tool, Byrant said in the post. The company added that Ruytenberg did not demonstrate successful attacks against machines with the DMA tool enabled.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above news article has been taken from [CNN Business News](https://edition.cnn.com/2020/05/12/tech/intel-thunderbolt-security-vulnerability/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict news type \n",
    "\n",
    "def predict_news_cnn(title, author, text):\n",
    "    # Lower case\n",
    "    total_info = title + ' ' + author + ' ' + text\n",
    "    total_info = total_info.lower()\n",
    "    \n",
    "    # Removing punctuations\n",
    "    def Punctuation(string):\n",
    "        punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "        for x in string.lower():\n",
    "            if x in punctuations:\n",
    "                string = string.replace(x, \"\")\n",
    "        \n",
    "        return string\n",
    "    \n",
    "    total_info = Punctuation(total_info)\n",
    "    \n",
    "    # Eliminating extra spaces\n",
    "    total_info = total_info.replace('   ', ' ')\n",
    "    total_info = total_info.replace('  ', ' ')\n",
    "    \n",
    "    # Removing stopwords\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    word_tokens = word_tokenize(total_info) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    total_info = ''\n",
    "    for word in filtered_sentence:\n",
    "        total_info += word + ' '\n",
    "        \n",
    "    total_info = total_info.rstrip()\n",
    "    \n",
    "    # Loading tokenizer\n",
    "    tokenizer = pickle.load(open('pklFiles/tokenizer.pkl', 'rb'))\n",
    "    \n",
    "    # Defining variables for maxlen\n",
    "    MAX_SEQUENCE_LENGTH = 500\n",
    "    \n",
    "    test_sequence = tokenizer.texts_to_sequences([total_info])\n",
    "    \n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "    test_data = pad_sequences(test_sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    \n",
    "    # Loading CNN model\n",
    "    from tensorflow.keras.models import load_model\n",
    "    cnn_model = load_model('Trained Models/cnn_model.h5')\n",
    "    \n",
    "    # Prediction\n",
    "    predicted_label = cnn_model.predict(test_data)\n",
    "    \n",
    "    # Result\n",
    "    if int(predicted_label.round()[0][0]) == 1:\n",
    "        print(\"News is 'Reliable'.\")\n",
    "    else:\n",
    "        print(\"News is 'Unreliable'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News is 'Reliable'.\n"
     ]
    }
   ],
   "source": [
    "predict_news_cnn(title, author, text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
